{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e71ec89",
   "metadata": {},
   "source": [
    "Stephanie Chiang  \n",
    "DATA 620 Summer 2025  \n",
    "### Assignment Week 5 Part 2:\n",
    "# Document Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0edcb1a",
   "metadata": {},
   "source": [
    "In this project, I will use the [UCI Machine Learning Repository: Spambase Data Set](https://archive.ics.uci.edu/dataset/94/spambase) corpus of labeled spam and non-spam e-mails to predict whether or not a new document is spam.\n",
    "\n",
    "There are 58 features and 4601 instances in the data. Each column/feature in X is a word or character frequency or stats on the lengths of continuous capital letters. The target variable is binary, spam (1) or not spam (0). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "29074565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n",
      "4601\n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "spambase = fetch_ucirepo(id=94) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = spambase.data.features\n",
    "y = spambase.data.targets \n",
    "\n",
    "print(len(spambase.variables))\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fabf425",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "First, I will combine the columns into a single dataframe in order to shuffle the rows randomly. This is to ensure that the training and test sets are representative of the overall data. After shuffling, I will split the data back into features (X) and target variable (y).\n",
    "\n",
    "Next, I will set aside 500 instances for testing later, with the rest used for training. Below, I can confirm a fair distribution of the target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d2353db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "0    2463\n",
      "1    1638\n",
      "Name: count, dtype: int64\n",
      "Class\n",
      "0    325\n",
      "1    175\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Concat X and y into one DataFrame along columns\n",
    "combined_df = pd.concat([X, y], axis=1)\n",
    "\n",
    "# Shuffle rows\n",
    "shuffled_df = combined_df.sample(frac=1, random_state=101).reset_index(drop=True)\n",
    "\n",
    "# Split back into X dataframe and y series\n",
    "X_shuffled = shuffled_df[X.columns]\n",
    "y_shuffled = shuffled_df[y.columns[0]]\n",
    "\n",
    "# Split into training and test sets\n",
    "train_X, test_X = X_shuffled[:-500], X_shuffled[-500:]\n",
    "train_y, test_y = y_shuffled[:-500], y_shuffled[-500:]\n",
    "\n",
    "print(train_y.value_counts())\n",
    "print(test_y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6306c25e",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier\n",
    "\n",
    "Now we can build the classifer in NLTK using Naive Bayes. This function requires the data to be reformatted to a list of tuples, where each tuple contains a dictionary of features and the numeric label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "20217414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "train_set = [\n",
    "    (train_X.iloc[i].to_dict(), train_y.iloc[i])\n",
    "    for i in range(len(train_X))\n",
    "]\n",
    "\n",
    "test_set = [\n",
    "    (test_X.iloc[i].to_dict(), test_y.iloc[i])\n",
    "    for i in range(len(test_X))\n",
    "]\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748f58f8",
   "metadata": {},
   "source": [
    "Below, we evaluate the performance of the model. The accuracy is quite high at 0.882. Some of the most informative indicators of whether an email is spam or not include the number of consecutive capital letters and the frequency of words like \"free\" and \"receive\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d873729b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.882\n",
      "Most Informative Features\n",
      "capital_run_length_total = 5.0                 0 : 1      =     49.4 : 1.0\n",
      "          word_freq_free = 0.32                1 : 0      =     28.9 : 1.0\n",
      "       word_freq_receive = 0.1                 1 : 0      =     24.3 : 1.0\n",
      "           word_freq_000 = 0.34                1 : 0      =     24.2 : 1.0\n",
      "capital_run_length_total = 6.0                 0 : 1      =     20.8 : 1.0\n",
      "capital_run_length_total = 4.0                 0 : 1      =     19.3 : 1.0\n",
      "          word_freq_will = 0.7                 1 : 0      =     19.0 : 1.0\n",
      "         word_freq_order = 0.09                1 : 0      =     18.3 : 1.0\n",
      "        word_freq_remove = 0.05                1 : 0      =     18.2 : 1.0\n",
      "        word_freq_remove = 0.32                1 : 0      =     18.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "accuracy = nltk.classify.accuracy(classifier, test_set)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0042c42",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Using NLTK and our labeled dataset, we effectively trained a Naive Bayes classifier to classify documents with high accuracy. This model predicted whether new emails were spam or not based on the text features in the training data. The 0.882 accuracy indicates that the model was quite effective in distinguishing between spam and non-spam emails. This type of supervised machine learning can easily be applied to other datasets and classification tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
