{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b980b73",
   "metadata": {},
   "source": [
    "Stephanie Chiang  \n",
    "DATA 620 Summer 2025  \n",
    "### Project 3:\n",
    "# Gender Classifier for Names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b35f7a8",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "In ths project, I will build, test, evaluate and aim to improve upon a gender classifier for names using the Natural Language Toolkit (NLTK) library in Python. The goal is to have the model classify names as either male or female with the highest accuracy possible.\n",
    "\n",
    "First, the NLTK `names` Corpus is loaded, labeled and randomized before splitting into the following subsets: 500 for the test set, 500 for the dev-test set and the remaining 6944 for the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "dfbe9a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 500 6944\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import names\n",
    "from nltk.classify import apply_features\n",
    "import random\n",
    "\n",
    "random.seed(101)\n",
    "\n",
    "labeled_names = ([(name, 'male') for name in names.words('male.txt')] + [(name, 'female') for name in names.words('female.txt')])\n",
    "random.shuffle(labeled_names)\n",
    "\n",
    "test_names = labeled_names[:500]\n",
    "devtest_names = labeled_names[500:1000]\n",
    "train_names = labeled_names[1000:]\n",
    "\n",
    "print(len(test_names), len(devtest_names), len(train_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e90cf69",
   "metadata": {},
   "source": [
    "Next, a simple initial function is defined to extract the last 2 letters of each name to be used as gender features. This function returns a dictionary and will be applied to each subset of names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "eba34933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features(word):\n",
    "    return {'suffix1': word[-1:],\n",
    "            'suffix2': word[-2:]}\n",
    "\n",
    "train_set = apply_features(gender_features, train_names)\n",
    "devtest_set = apply_features(gender_features, devtest_names)\n",
    "test_set = apply_features(gender_features, test_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d99458",
   "metadata": {},
   "source": [
    "I will use NLTK's Naive Bayes classifier on the training set to create a model, then evaluate its accuracy against the dev-test set.\n",
    "\n",
    "The most informative features are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "570a54d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.764\n",
      "Most Informative Features\n",
      "                 suffix2 = 'na'           female : male   =    155.5 : 1.0\n",
      "                 suffix2 = 'la'           female : male   =     71.7 : 1.0\n",
      "                 suffix2 = 'rt'             male : female =     51.8 : 1.0\n",
      "                 suffix1 = 'k'              male : female =     43.2 : 1.0\n",
      "                 suffix1 = 'a'            female : male   =     37.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "print(nltk.classify.accuracy(classifier, devtest_set))\n",
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733d0ae8",
   "metadata": {},
   "source": [
    "The accuracy is already decent at 0.764, but we can examine which names were incorrectly classified by printing some of the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "232a407e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('female', 'Joellen'), ('male', 'Filipe'), ('female', 'Inez'), ('female', 'Ingaborg'), ('male', 'Simone'), ('female', 'Gillan'), ('female', 'Colleen'), ('male', 'Ellsworth'), ('male', 'Donnie'), ('female', 'Kristien')]\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "for (name, tag) in devtest_names:\n",
    "    guess = classifier.classify(gender_features(name))\n",
    "    if guess != tag:\n",
    "        errors.append((tag, name))\n",
    "\n",
    "print(errors[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d87316",
   "metadata": {},
   "source": [
    "A quick visual inspection of the errors shows that many of the names are less common to English-speakers or ambiguous even to human eyes, which may be contributing to the misclassifications.\n",
    "\n",
    "To improve on the classifier, I will include the first 2 letters as features as well. This improves the accuracy to 0.816 but does not change the most informative features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2433ddab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.816\n",
      "Most Informative Features\n",
      "                 suffix2 = 'na'           female : male   =    155.5 : 1.0\n",
      "                 suffix2 = 'la'           female : male   =     71.7 : 1.0\n",
      "                 suffix2 = 'rt'             male : female =     51.8 : 1.0\n",
      "                 suffix1 = 'k'              male : female =     43.2 : 1.0\n",
      "                 suffix1 = 'a'            female : male   =     37.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "def gender_features2(word):\n",
    "    return {'suffix1': word[-1:],\n",
    "            'suffix2': word[-2:],\n",
    "            'prefix1': word[:1],\n",
    "            'prefix2': word[:2]}\n",
    "\n",
    "train_set2 = apply_features(gender_features2, train_names)\n",
    "devtest_set2 = apply_features(gender_features2, devtest_names)\n",
    "test_set2 = apply_features(gender_features2, test_names)\n",
    "\n",
    "classifier2 = nltk.NaiveBayesClassifier.train(train_set2)\n",
    "print(nltk.classify.accuracy(classifier2, devtest_set2))\n",
    "classifier2.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f9d19d",
   "metadata": {},
   "source": [
    "I thought it would be interesting and more informative to examine how the suffixes and prefixes work in combination, so a simple concatenation of the first and last letters is added to the feature function. This makes almost no impact on accuracy, but the informative features now include some of these combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b4919ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.812\n",
      "Most Informative Features\n",
      "                 suffix2 = 'na'           female : male   =    155.5 : 1.0\n",
      "                 suffix2 = 'la'           female : male   =     71.7 : 1.0\n",
      "              first-last = 'Aa'           female : male   =     66.0 : 1.0\n",
      "              first-last = 'Ca'           female : male   =     52.3 : 1.0\n",
      "                 suffix2 = 'rt'             male : female =     51.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "def gender_features3(word):\n",
    "    return {'suffix1': word[-1:],\n",
    "            'suffix2': word[-2:],\n",
    "            'prefix1': word[:1],\n",
    "            'prefix2': word[:2],\n",
    "            'first-last': word[0] + word[-1]}\n",
    "\n",
    "train_set3 = apply_features(gender_features3, train_names)\n",
    "devtest_set3 = apply_features(gender_features3, devtest_names)\n",
    "test_set3 = apply_features(gender_features3, test_names)\n",
    "\n",
    "classifier3 = nltk.NaiveBayesClassifier.train(train_set3)\n",
    "print(nltk.classify.accuracy(classifier3, devtest_set3))\n",
    "classifier3.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed8bc63",
   "metadata": {},
   "source": [
    "The performance of this classifier on the final test set is evaluated below, with an accuracy of 0.78. This is expected, since I was working with the dev-test set on the previous iterations to improve the model, which could naturally lead to some overfitting on the data. The model is still performing slightly better than the initial iteration of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "04a62865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier3, test_set3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3313d66d",
   "metadata": {},
   "source": [
    "As one last test, I will compare the performance of the Naive Bayes classifier to a Decision Tree classifier. The Decision Tree classifier has an accuracy of 0.776 when trained with the original feature set of only the last 2 letters of each name, which is slightly better than the my first Naive Bayes. However, the Decision Tree performance actually drops when the additional features of the prefixes or the combinations of first and last letters are included, to a 0.722. \n",
    "\n",
    "A final accuracy score for the decision tree is generated on the original test set and unaltered features, and we get the same performance of 0.78 as on the final version of Naive Bayes classifier. To me, this is a good sign that the data itself may be the limiting factor for improvement, rather than any tweaks that we can make to the features or classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d21a78bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.776\n",
      "0.722\n",
      "0.78\n"
     ]
    }
   ],
   "source": [
    "classifier_dt = nltk.DecisionTreeClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier_dt, devtest_set))\n",
    "\n",
    "classifier_dt3 = nltk.DecisionTreeClassifier.train(train_set3)\n",
    "print(nltk.classify.accuracy(classifier_dt3, devtest_set3))\n",
    "\n",
    "print(nltk.classify.accuracy(classifier_dt, test_set))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
